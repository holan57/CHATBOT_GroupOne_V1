import os
import sys
import io
import streamlit as st
import google.generativeai as genai
from gtts import gTTS  # éœ€å®‰è£: pip install gTTS

# å°‡çˆ¶ç›®éŒ„åŠ å…¥ sys.path ä»¥ä¾¿åŒ¯å…¥ chatbot_logic
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# åŒ¯å…¥æ¨¡çµ„åŒ–çš„é‚è¼¯
from chatbot_logic import GeminiChatService

# è¨­å®š Streamlit é é¢
st.set_page_config(page_title="Gemini ChatBot (èªéŸ³ç‰ˆ)", page_icon="ğŸ¤–", layout="centered")
st.title("Gemini ChatBot (èªéŸ³ç‰ˆ)")

# å´é‚Šæ¬„ï¼šæ¨¡å‹é¸æ“‡
with st.sidebar:
    st.header("è¨­å®š")
    # æ–°å¢ API Key è¼¸å…¥æ¬„ä½
    api_key = st.text_input("è«‹è¼¸å…¥ Google API Key", type="password")
    
    # ä½¿ç”¨ç›®å‰æœ‰æ•ˆçš„æ¨¡å‹åˆ—è¡¨
    model_options = ["gemini-2.5-flash-tts"]

    if api_key:
        # ä½¿ç”¨ .strip() å»é™¤å¯èƒ½ä¸å°å¿ƒè¤‡è£½åˆ°çš„æ›è¡Œç¬¦è™Ÿæˆ–ç©ºç™½
        os.environ["GOOGLE_API_KEY"] = api_key.strip()

    selected_model = st.selectbox("é¸æ“‡æ¨¡å‹", model_options, index=0)

# æª¢æŸ¥æ˜¯å¦å·²è¨­å®š API Key
if not os.environ.get("GOOGLE_API_KEY"):
    st.warning("è«‹å…ˆåœ¨å·¦å´æ¬„ä½è¼¸å…¥ Google API Key æ‰èƒ½å•Ÿå‹•èŠå¤©æ©Ÿå™¨äºº")
    st.stop()

# åˆå§‹åŒ–æˆ–æ›´æ–° Chat Service
if "chat_service" not in st.session_state or st.session_state.get("current_model") != selected_model:
    st.session_state.current_model = selected_model
    st.session_state.chat_service = GeminiChatService(model_name=selected_model)
    st.session_state.chat_service.start_chat(history=[])

if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.chat_service.start_chat(history=[])

# å´é‚Šæ¬„ï¼šåŠŸèƒ½æŒ‰éˆ•
with st.sidebar:
    if st.button("æ¸…é™¤ç´€éŒ„", type="primary"):
        st.session_state.messages = []
        st.session_state.chat_service.start_chat(history=[])
        st.rerun()

# é¡¯ç¤ºå°è©±ç´€éŒ„
for message in st.session_state.messages:
    role = message.get("role", "user")
    if role == "model":
        role = "assistant"
    
    with st.chat_message(role):
        st.markdown(message.get("content", ""))

# è™•ç†ä½¿ç”¨è€…è¼¸å…¥
if prompt := st.chat_input("è«‹è¼¸å…¥è¨Šæ¯..."):
    # 1. é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. é¡¯ç¤º AI å›æ‡‰
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # å‘¼å« ChatService å–å¾—å›æ‡‰ä¸²æµ
            response_stream = st.session_state.chat_service.send_message(prompt)
            
            for chunk in response_stream:
                if hasattr(chunk, 'text'):
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "model", "content": full_response})

            # 3. TTS èªéŸ³ç”Ÿæˆèˆ‡æ’­æ”¾
            try:
                # å°‡æ–‡å­—è½‰ç‚ºèªéŸ³ (lang='zh-tw' ç‚ºä¸­æ–‡ï¼Œå¯ä¾éœ€æ±‚æ”¹ç‚º 'en')
                tts = gTTS(text=full_response, lang='zh-tw')
                audio_fp = io.BytesIO()
                tts.write_to_fp(audio_fp)
                st.audio(audio_fp, format='audio/mp3')
            except Exception as e:
                st.warning(f"ç„¡æ³•ç”¢ç”ŸèªéŸ³: {e}")
                
        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")